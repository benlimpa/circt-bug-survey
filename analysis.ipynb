{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIRCT Issue Statistics\n",
    "\n",
    "This notebooks analyzes the Github issues exported using [Github CSV Tools](https://github.com/gavinr/github-csv-tools).\n",
    "\n",
    "Since the CSV Tools exports the issues, pull requests, and associated comments as a single CSV file, we first normalize the data into separate dataframes for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw export\n",
    "df = pd.read_csv(\"2023-01-06-14-25-56-issues.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all columns\n",
    "# note that not all rows will have an entry for each column\n",
    "df.columns.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to one of the following:\n",
    "- An issue: A row corresponding to an issue contains values for `issue.*` columns\n",
    "- A pull request: A row corresponding to a PR has values for the same columns as issues, but the `issue.html_url` is `https://github.com/llvm/circt/pull/<pr_id>` rather than `https://github.com/llvm/circt/pull/<issue_id>`\n",
    "- A comment: A row corresponding to a comment on an issue or a pull request inherits all the same fields as the issue or pull request, except that the `comment.*` fields are also populated.\n",
    "\n",
    "Using these facts, we can separate the issues from the pull requests by inspecting the `issue.html_url`; and separate the comments from the parent issue/PR by checking if any of the `comment.*` fields are populated or contain `NaN`.\n",
    "\n",
    "Other notable fields of interest are as follows:\n",
    "- `issue.url`: The Github API url to retrieve this issue/PR/comment. All rows are guaranteed to contain this field so we can use this to uniquely index issue/PR threads. However, we must filter out the associated comment rows before calculating statistics.\n",
    "- `issue.labels`: A JSON-encoded list of labels assigned to this issue/PR. This is how we will filter out issues that correspond to bugs and determine which component of CIRCT the issue is associated with.\n",
    "- `issue.body`: The text description of the issue.\n",
    "- `comment.body`: The text of the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only closed issues\n",
    "closed_filter = ~pd.isna(df[\"issue.closed_at\"])\n",
    "closed_prs_and_issues = df[closed_filter]\n",
    "# separate pull requests and issues\n",
    "pr_filter = closed_prs_and_issues[\"issue.html_url\"].str.contains(\"pull\")\n",
    "prs_and_comments = closed_prs_and_issues[pr_filter]\n",
    "issues_and_comments = closed_prs_and_issues[~pr_filter]\n",
    "\n",
    "# separate comments from pull requests\n",
    "pr_comment_filter = pd.isna(prs_and_comments[\"comment.created_at\"])\n",
    "prs = prs_and_comments[pr_comment_filter]\n",
    "pr_comments = prs_and_comments[~pr_comment_filter]\n",
    "\n",
    "# separate comments from issues\n",
    "issue_comment_filter = pd.isna(issues_and_comments[\"comment.created_at\"])\n",
    "issues = issues_and_comments[issue_comment_filter]\n",
    "issue_comments = issues_and_comments[~issue_comment_filter]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since multiple opened issues can correspond to the same bug, we index by pull requests (making the assumption that a pull request that links to one or more issues tagged as bugs represents fixing a single common bug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_label(item, label_name):\n",
    "    labels = json.loads(item)\n",
    "    for label in labels:\n",
    "        if label[\"name\"] == label_name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_bug(item):\n",
    "    return has_label(item, \"bug\")\n",
    "bug_mask = issues[\"issue.labels\"].apply(is_bug)\n",
    "bug_issues = issues[bug_mask]\n",
    "bug_numbers = bug_issues[\"issue.number\"]\n",
    "# save this to a file so that we can reference these issues manually later\n",
    "bug_numbers.to_csv(\"bug_numbers.csv\")\n",
    "bug_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the labels that are associated with issues that are labeled as bugs\n",
    "all_bug_labels = set()\n",
    "for idx, bug in bug_issues.iterrows():\n",
    "    labels = json.loads(bug[\"issue.labels\"])\n",
    "    for label in labels:\n",
    "        name = label[\"name\"]\n",
    "        if name not in all_bug_labels:\n",
    "            all_bug_labels.add(name)\n",
    "all_bug_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bugs = len(bug_issues)\n",
    "print(f\"Total Bug Issues: {total_bugs}\")\n",
    "for bug_label in all_bug_labels:\n",
    "    label_count = bug_issues[\"issue.labels\"].apply(lambda item: has_label(item, bug_label)).sum()\n",
    "    print(f\"Label: {bug_label}, Count: {label_count}, Proportion: {label_count/total_bugs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_plot = list(all_bug_labels)\n",
    "labels_to_plot.remove(\"bug\")\n",
    "labels_to_plot.remove(\"good first issue\")\n",
    "x = list()\n",
    "y = list()\n",
    "for bug_label in list(labels_to_plot):\n",
    "    x.append(bug_label)\n",
    "    label_count = bug_issues[\"issue.labels\"].apply(lambda item: has_label(item, bug_label)).sum()\n",
    "    y.append(label_count)\n",
    "data = pd.DataFrame({\"Issue Label\": x, \"Number of Occurences\": y})\n",
    "data.sort_values(by=\"Number of Occurences\", ascending=False, inplace=True)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=70)\n",
    "ax = sns.barplot(data=data, x=\"Issue Label\", y=\"Number of Occurences\")\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find all pull requests that mention an issue (assumption is that a PR\n",
    "### mentioning an issue == a PR fixing said issue)\n",
    "\n",
    "# first we extract the mentioned issue numbers from each PR\n",
    "mentioned_numbers = prs[\"issue.body\"].str.extractall(\"#(\\d{1,4})\")[0]\n",
    "mentioned_numbers_comments = pr_comments[\"comment.body\"].str.extractall(\"#(\\d{1,4})\")[0]\n",
    "# the extractall function returns one match per row. Each row is index with a\n",
    "# multi-index where the first index is the original row index, and the second\n",
    "# index is the match # (starting from zero)\n",
    "\n",
    "# we turn these series of mentioned numbers into a boolean mask that\n",
    "# selects PRs that mention an issue tagged as a bug\n",
    "def does_mention_bug(numbers):\n",
    "    \"\"\"Checks if the given list of numbers references an issue labeled as a bug\"\"\"\n",
    "    numbers = numbers.apply(int).values.flatten()\n",
    "    for num in numbers:\n",
    "        if num in bug_numbers.values:\n",
    "            return True\n",
    "    return False        \n",
    "mention_filter_data = list()\n",
    "for idx in prs.index:\n",
    "    mentions_bug = False\n",
    "    # check if the pr mentions a number in the body text\n",
    "    if (idx, 0) in mentioned_numbers.index:\n",
    "        mentions_bug |= does_mention_bug(mentioned_numbers.loc[idx])\n",
    "    # check if the pr mentions a number in a comment\n",
    "    if (idx, 0) in mentioned_numbers_comments.index:\n",
    "        mentions_bug |= does_mention_bug(mentioned_numbers_comments.loc[idx])\n",
    "    mention_filter_data.append(mentions_bug)\n",
    "mention_filter = pd.Series(data=mention_filter_data, index=prs.index)\n",
    "\n",
    "prs_that_mention = prs[mention_filter]\n",
    "prs_that_mention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only find 81 PRs that satisfy this. This seems like too low of a number to be correct. Maybe looking for mentions of issues within the PR body and comments is not a reliable way of matching PRs to issues.\n",
    "\n",
    "However, in Github's web UI, many of the issues are linked to a pull request even if it's not explicitly mentioned in the actual description. We may want to look into the Github API to see if there's a way to extract this information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circt-bug-survey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "211b6134d71317e1ec4606ac02877e7aee540f7023219b113c9af77ac37ac062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
